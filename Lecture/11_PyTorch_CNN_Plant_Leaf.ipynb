{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElaYJ/Study_Deep_Learning/blob/main/Lecture/11_PyTorch_CNN_Plant_Leaf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFoVtUyf_OeJ"
      },
      "source": [
        "# 식물잎의 사진으로 질병 분류\n",
        "\n",
        "- 이 자료는 병든 작물잎 사진을 이용해 질병의 유무를 판단하는 분류문제로 kaggle에서 좋은 평가를 받은 코드를 가지고 해설한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqCTHaiJmtrz"
      },
      "source": [
        "<br></br>\n",
        "\n",
        "## - 파일 정리\n",
        "\n",
        "- https://drive.google.com/file/d/1tzhqc3384i5bd_OIX95ACYkaB44ZpxKj/view?usp=sharing\n",
        "\n",
        "- 데이터를 받아서 구글 드라이브에 올리고 압축을 풀어서 나의 colab 폴더에 둔다.\n",
        "\n",
        "- 4만 장 사진 데이터 (balance가 잘 맞지는 않는다.)\n",
        "\n",
        "    <img src=\"https://github.com/ElaYJ/supplement/assets/153154981/d4276a45-db5e-4781-b23b-5f24f2f1178b\" width=\"57%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm_uierI-mem",
        "outputId": "529ec734-91d2-4d87-c25a-f5a0fe7221fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "잔여시간 : 11.88"
          ]
        }
      ],
      "source": [
        "!cat /proc/uptime | awk '{printf(\"잔여시간 : %.2f\", 12-$1/60/60)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0tHsUKf-8hL",
        "outputId": "b4d67273-605d-452e-adca-40b4e8139990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Apr 12 16:37:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u12ASieoskh",
        "outputId": "c303b286-868d-49a1-8163-a49e47ec2e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브에 접근\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Co88D0Vc_Aqn"
      },
      "outputs": [],
      "source": [
        "# -d --> 압축을 푸는 경로 지정\n",
        "\n",
        "!unzip -qq \"/content/drive/MyDrive/zero-base DS/dataset.zip\" -d './dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT66dwsPy1vH",
        "outputId": "be20a22f-7316-470a-e0d1-87fdf0162c15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Tomato___healthy',\n",
              " 'Tomato___Late_blight',\n",
              " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
              " 'Pepper,_bell___healthy',\n",
              " 'Potato___Early_blight',\n",
              " 'Strawberry___Leaf_scorch',\n",
              " 'Grape___healthy',\n",
              " 'Tomato___Bacterial_spot',\n",
              " 'Cherry___Powdery_mildew',\n",
              " 'Corn___Common_rust',\n",
              " 'Tomato___Early_blight',\n",
              " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
              " 'Tomato___Tomato_mosaic_virus',\n",
              " 'Tomato___Target_Spot',\n",
              " 'Potato___healthy',\n",
              " 'Potato___Late_blight',\n",
              " 'Cherry___healthy',\n",
              " 'Pepper,_bell___Bacterial_spot',\n",
              " 'Grape___Black_rot',\n",
              " 'Peach___Bacterial_spot',\n",
              " 'Strawberry___healthy',\n",
              " 'Corn___healthy',\n",
              " 'Tomato___Leaf_Mold',\n",
              " 'Apple___Black_rot',\n",
              " 'Apple___Apple_scab',\n",
              " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
              " 'Corn___Northern_Leaf_Blight',\n",
              " 'Grape___Esca_(Black_Measles)',\n",
              " 'Tomato___Septoria_leaf_spot',\n",
              " 'Apple___healthy',\n",
              " 'Apple___Cedar_apple_rust',\n",
              " 'Corn___Cercospora_leaf_spot Gray_leaf_spot',\n",
              " 'Peach___healthy']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "original_dataset_dir = './dataset'\n",
        "classes_list = os.listdir(original_dataset_dir)\n",
        "classes_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DLvzig7Yzo6e"
      },
      "outputs": [],
      "source": [
        "base_dir = './splitted'\n",
        "os.mkdir(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Qs1UOZZlz1ak"
      },
      "outputs": [],
      "source": [
        "# 데이터 정리를 위한 목록 및 폴더 생성\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'valid')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list:\n",
        "    os.mkdir(os.path.join(train_dir, cls))\n",
        "    os.mkdir(os.path.join(validation_dir, cls))\n",
        "    os.mkdir(os.path.join(test_dir, cls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYq3ECec1En7",
        "outputId": "819abcbf-1caf-48e1-82b8-65bfd3a3615a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size( Tomato___healthy ) 954\n",
            "Valid size( Tomato___healthy ) 318\n",
            "Test size( Tomato___healthy ) 318\n",
            "Train size( Tomato___Late_blight ) 1145\n",
            "Valid size( Tomato___Late_blight ) 381\n",
            "Test size( Tomato___Late_blight ) 381\n",
            "Train size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ) 3214\n",
            "Valid size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ) 1071\n",
            "Test size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ) 1071\n",
            "Train size( Pepper,_bell___healthy ) 886\n",
            "Valid size( Pepper,_bell___healthy ) 295\n",
            "Test size( Pepper,_bell___healthy ) 295\n",
            "Train size( Potato___Early_blight ) 600\n",
            "Valid size( Potato___Early_blight ) 200\n",
            "Test size( Potato___Early_blight ) 200\n",
            "Train size( Strawberry___Leaf_scorch ) 665\n",
            "Valid size( Strawberry___Leaf_scorch ) 221\n",
            "Test size( Strawberry___Leaf_scorch ) 221\n",
            "Train size( Grape___healthy ) 253\n",
            "Valid size( Grape___healthy ) 84\n",
            "Test size( Grape___healthy ) 84\n",
            "Train size( Tomato___Bacterial_spot ) 1276\n",
            "Valid size( Tomato___Bacterial_spot ) 425\n",
            "Test size( Tomato___Bacterial_spot ) 425\n",
            "Train size( Cherry___Powdery_mildew ) 631\n",
            "Valid size( Cherry___Powdery_mildew ) 210\n",
            "Test size( Cherry___Powdery_mildew ) 210\n",
            "Train size( Corn___Common_rust ) 715\n",
            "Valid size( Corn___Common_rust ) 238\n",
            "Test size( Corn___Common_rust ) 238\n",
            "Train size( Tomato___Early_blight ) 600\n",
            "Valid size( Tomato___Early_blight ) 200\n",
            "Test size( Tomato___Early_blight ) 200\n",
            "Train size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ) 645\n",
            "Valid size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ) 215\n",
            "Test size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ) 215\n",
            "Train size( Tomato___Tomato_mosaic_virus ) 223\n",
            "Valid size( Tomato___Tomato_mosaic_virus ) 74\n",
            "Test size( Tomato___Tomato_mosaic_virus ) 74\n",
            "Train size( Tomato___Target_Spot ) 842\n",
            "Valid size( Tomato___Target_Spot ) 280\n",
            "Test size( Tomato___Target_Spot ) 280\n",
            "Train size( Potato___healthy ) 91\n",
            "Valid size( Potato___healthy ) 30\n",
            "Test size( Potato___healthy ) 30\n",
            "Train size( Potato___Late_blight ) 600\n",
            "Valid size( Potato___Late_blight ) 200\n",
            "Test size( Potato___Late_blight ) 200\n",
            "Train size( Cherry___healthy ) 512\n",
            "Valid size( Cherry___healthy ) 170\n",
            "Test size( Cherry___healthy ) 170\n",
            "Train size( Pepper,_bell___Bacterial_spot ) 598\n",
            "Valid size( Pepper,_bell___Bacterial_spot ) 199\n",
            "Test size( Pepper,_bell___Bacterial_spot ) 199\n",
            "Train size( Grape___Black_rot ) 708\n",
            "Valid size( Grape___Black_rot ) 236\n",
            "Test size( Grape___Black_rot ) 236\n",
            "Train size( Peach___Bacterial_spot ) 1378\n",
            "Valid size( Peach___Bacterial_spot ) 459\n",
            "Test size( Peach___Bacterial_spot ) 459\n",
            "Train size( Strawberry___healthy ) 273\n",
            "Valid size( Strawberry___healthy ) 91\n",
            "Test size( Strawberry___healthy ) 91\n",
            "Train size( Corn___healthy ) 697\n",
            "Valid size( Corn___healthy ) 232\n",
            "Test size( Corn___healthy ) 232\n",
            "Train size( Tomato___Leaf_Mold ) 571\n",
            "Valid size( Tomato___Leaf_Mold ) 190\n",
            "Test size( Tomato___Leaf_Mold ) 190\n",
            "Train size( Apple___Black_rot ) 372\n",
            "Valid size( Apple___Black_rot ) 124\n",
            "Test size( Apple___Black_rot ) 124\n",
            "Train size( Apple___Apple_scab ) 378\n",
            "Valid size( Apple___Apple_scab ) 126\n",
            "Test size( Apple___Apple_scab ) 126\n",
            "Train size( Tomato___Spider_mites Two-spotted_spider_mite ) 1005\n",
            "Valid size( Tomato___Spider_mites Two-spotted_spider_mite ) 335\n",
            "Test size( Tomato___Spider_mites Two-spotted_spider_mite ) 335\n",
            "Train size( Corn___Northern_Leaf_Blight ) 591\n",
            "Valid size( Corn___Northern_Leaf_Blight ) 197\n",
            "Test size( Corn___Northern_Leaf_Blight ) 197\n",
            "Train size( Grape___Esca_(Black_Measles) ) 829\n",
            "Valid size( Grape___Esca_(Black_Measles) ) 276\n",
            "Test size( Grape___Esca_(Black_Measles) ) 276\n",
            "Train size( Tomato___Septoria_leaf_spot ) 1062\n",
            "Valid size( Tomato___Septoria_leaf_spot ) 354\n",
            "Test size( Tomato___Septoria_leaf_spot ) 354\n",
            "Train size( Apple___healthy ) 987\n",
            "Valid size( Apple___healthy ) 329\n",
            "Test size( Apple___healthy ) 329\n",
            "Train size( Apple___Cedar_apple_rust ) 165\n",
            "Valid size( Apple___Cedar_apple_rust ) 55\n",
            "Test size( Apple___Cedar_apple_rust ) 55\n",
            "Train size( Corn___Cercospora_leaf_spot Gray_leaf_spot ) 307\n",
            "Valid size( Corn___Cercospora_leaf_spot Gray_leaf_spot ) 102\n",
            "Test size( Corn___Cercospora_leaf_spot Gray_leaf_spot ) 102\n",
            "Train size( Peach___healthy ) 216\n",
            "Valid size( Peach___healthy ) 72\n",
            "Test size( Peach___healthy ) 72\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import shutil\n",
        "\n",
        "# 데이터 현황 확인\n",
        "for cls in classes_list:\n",
        "    path = os.path.join(original_dataset_dir, cls)\n",
        "    fnames = os.listdir(path)\n",
        "\n",
        "    train_size = math.floor(len(fnames) * 0.6)\n",
        "    valid_size = math.floor(len(fnames) * 0.2)\n",
        "    test_size = math.floor(len(fnames) * 0.2)\n",
        "\n",
        "    train_fnames = fnames[:train_size]\n",
        "    print(\"Train size(\",cls,\")\", len(train_fnames))\n",
        "    for fname in train_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(train_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    valid_fnames = fnames[train_size:(train_size + valid_size)]\n",
        "    print(\"Valid size(\",cls,\")\", len(valid_fnames))\n",
        "    for fname in valid_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    test_fnames = fnames[(train_size + valid_size):(train_size + valid_size + test_size)]\n",
        "    print(\"Test size(\",cls,\")\", len(test_fnames))\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efof--Lt6RWb"
      },
      "source": [
        "<br></br>\n",
        "\n",
        "## - 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiMMwdfq4ZXv",
        "outputId": "b1f9eaad-9ed4-4627-c8e9-16f1c81c9230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"CPU\")\n",
        "print(DEVICE)\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ojPrFgFf66Nx"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "transform_base = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
        "train_dataset = ImageFolder(root='./splitted/train', transform=transform_base)\n",
        "valid_dataset = ImageFolder(root='./splitted/valid', transform=transform_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rgJtEBmOIk4",
        "outputId": "c855ef14-98ea-472f-b537-7b435f0a4005"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "W93qBsMtO3st"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.fc1 = nn.Linear(4096, 512)\n",
        "        self.fc2 = nn.Linear(512, 33) #--> class가 33개임.\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.dropout(x, p=0.25, training=self.training) #--> train data만 적용\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "        x = x.view(-1, 4096) #--> Flatten과 동일\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.25, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XR2TKiBERHZ_"
      },
      "outputs": [],
      "source": [
        "model_base = Net().to(DEVICE)\n",
        "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zGendJPhRYSN"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE) #--> data, target을 Device로 보낸다.\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward() #--> 역전파\n",
        "        optimizer.step() #--> weight update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cEPKnk2CSVzc"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad(): #--> 모델을 평가할 때는 가중치를 업데이트하면 안된다.\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IrutDqx-UPsa"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "def train_baseline(model, train_loader, valid_loader, optimizer, num_epochs = 30):\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) #--> 정확도가 가장 높은 모델의 가중치 저장\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        since = time.time()\n",
        "        train(model, train_loader, optimizer)\n",
        "        train_loss, train_acc = evaluate(model, train_loader)\n",
        "        valid_loss, valid_acc = evaluate(model, valid_loader)\n",
        "\n",
        "        # 30번째 epoch의 모델이 Best 모델이라는 보장이 없다.\n",
        "        if valid_acc > best_acc:\n",
        "            best_acc = valid_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('------------------ epoch {} ------------------'.format(epoch))\n",
        "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))\n",
        "        print('valid Loss: {:.4f}, Accuracy: {:.2f}%'.format(valid_loss, valid_acc))\n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MEkd0I8W81-",
        "outputId": "8caffc35-bd51-4ad7-e8eb-39861b2801ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------ epoch 1 ------------------\n",
            "train Loss: 1.5231, Accuracy: 56.38%\n",
            "valid Loss: 1.5465, Accuracy: 55.49%\n",
            "Completed in 1.000000m 7s\n",
            "------------------ epoch 2 ------------------\n",
            "train Loss: 0.9729, Accuracy: 69.79%\n",
            "valid Loss: 1.0073, Accuracy: 68.67%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 3 ------------------\n",
            "train Loss: 0.7857, Accuracy: 74.67%\n",
            "valid Loss: 0.8400, Accuracy: 73.24%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 4 ------------------\n",
            "train Loss: 0.6929, Accuracy: 77.78%\n",
            "valid Loss: 0.7522, Accuracy: 75.94%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 5 ------------------\n",
            "train Loss: 0.4559, Accuracy: 85.41%\n",
            "valid Loss: 0.5243, Accuracy: 82.68%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 6 ------------------\n",
            "train Loss: 0.4255, Accuracy: 86.60%\n",
            "valid Loss: 0.5070, Accuracy: 83.98%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 7 ------------------\n",
            "train Loss: 0.3362, Accuracy: 89.50%\n",
            "valid Loss: 0.4275, Accuracy: 86.29%\n",
            "Completed in 1.000000m 3s\n",
            "------------------ epoch 8 ------------------\n",
            "train Loss: 0.3461, Accuracy: 88.79%\n",
            "valid Loss: 0.4598, Accuracy: 84.82%\n",
            "Completed in 1.000000m 0s\n",
            "------------------ epoch 9 ------------------\n",
            "train Loss: 0.3779, Accuracy: 87.49%\n",
            "valid Loss: 0.5019, Accuracy: 83.99%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 10 ------------------\n",
            "train Loss: 0.2276, Accuracy: 92.95%\n",
            "valid Loss: 0.3503, Accuracy: 88.55%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 11 ------------------\n",
            "train Loss: 0.2101, Accuracy: 93.58%\n",
            "valid Loss: 0.3391, Accuracy: 88.62%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 12 ------------------\n",
            "train Loss: 0.1729, Accuracy: 94.83%\n",
            "valid Loss: 0.3121, Accuracy: 89.64%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 13 ------------------\n",
            "train Loss: 0.1657, Accuracy: 95.01%\n",
            "valid Loss: 0.3099, Accuracy: 89.59%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 14 ------------------\n",
            "train Loss: 0.1378, Accuracy: 95.96%\n",
            "valid Loss: 0.2851, Accuracy: 90.44%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 15 ------------------\n",
            "train Loss: 0.1153, Accuracy: 96.79%\n",
            "valid Loss: 0.2638, Accuracy: 91.24%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 16 ------------------\n",
            "train Loss: 0.1034, Accuracy: 96.99%\n",
            "valid Loss: 0.2567, Accuracy: 91.50%\n",
            "Completed in 1.000000m 3s\n",
            "------------------ epoch 17 ------------------\n",
            "train Loss: 0.1006, Accuracy: 97.28%\n",
            "valid Loss: 0.2512, Accuracy: 91.59%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 18 ------------------\n",
            "train Loss: 0.1004, Accuracy: 97.00%\n",
            "valid Loss: 0.2697, Accuracy: 91.06%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 19 ------------------\n",
            "train Loss: 0.0944, Accuracy: 97.33%\n",
            "valid Loss: 0.2637, Accuracy: 91.43%\n",
            "Completed in 1.000000m 3s\n",
            "------------------ epoch 20 ------------------\n",
            "train Loss: 0.0688, Accuracy: 98.26%\n",
            "valid Loss: 0.2330, Accuracy: 92.33%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 21 ------------------\n",
            "train Loss: 0.0574, Accuracy: 98.50%\n",
            "valid Loss: 0.2342, Accuracy: 92.69%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 22 ------------------\n",
            "train Loss: 0.0485, Accuracy: 98.90%\n",
            "valid Loss: 0.2151, Accuracy: 93.05%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 23 ------------------\n",
            "train Loss: 0.0384, Accuracy: 99.17%\n",
            "valid Loss: 0.2049, Accuracy: 93.58%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 24 ------------------\n",
            "train Loss: 0.0695, Accuracy: 97.82%\n",
            "valid Loss: 0.2618, Accuracy: 91.79%\n",
            "Completed in 1.000000m 2s\n",
            "------------------ epoch 25 ------------------\n",
            "train Loss: 0.0447, Accuracy: 99.09%\n",
            "valid Loss: 0.2192, Accuracy: 93.02%\n",
            "Completed in 1.000000m 3s\n",
            "------------------ epoch 26 ------------------\n",
            "train Loss: 0.0413, Accuracy: 99.12%\n",
            "valid Loss: 0.2206, Accuracy: 93.10%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 27 ------------------\n",
            "train Loss: 0.0673, Accuracy: 97.89%\n",
            "valid Loss: 0.2881, Accuracy: 91.00%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 28 ------------------\n",
            "train Loss: 0.0355, Accuracy: 99.10%\n",
            "valid Loss: 0.2228, Accuracy: 92.97%\n",
            "Completed in 1.000000m 3s\n",
            "------------------ epoch 29 ------------------\n",
            "train Loss: 0.0575, Accuracy: 98.36%\n",
            "valid Loss: 0.2681, Accuracy: 91.65%\n",
            "Completed in 1.000000m 1s\n",
            "------------------ epoch 30 ------------------\n",
            "train Loss: 0.0253, Accuracy: 99.50%\n",
            "valid Loss: 0.2110, Accuracy: 93.68%\n",
            "Completed in 1.000000m 1s\n"
          ]
        }
      ],
      "source": [
        "base = train_baseline(model_base, train_loader, valid_loader, optimizer, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RDRTMCoPXXNs"
      },
      "outputs": [],
      "source": [
        "torch.save(base, 'baseline.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
